import torch
from torch import tensor

# def collate_fn(batch):
#     # 获取 batch 中第一个张量的大小
#     sizes = [tensor.size() for tensor in batch]
#     max_size = tuple(max(s) for s in zip(*sizes))
#
#     # 根据最大尺寸进行填充或截断
#     padded_batch = []
#     for tensor in batch:
#         pad_tensor = torch.nn.functional.pad(tensor, (0, max_size[0] - tensor.size(0)))
#         padded_batch.append(pad_tensor)
#
#     return torch.stack(padded_batch)
#
# # 示例用法
# batch = [torch.tensor([1, 2, 3]), torch.tensor([4, 5]), torch.tensor([6, 7, 8, 9])]
# padded_batch = collate_fn(batch)
# print(padded_batch)

'''
a = [tensor([[37564,    11,   314,   892,   314,  1053,   587, 29419,    13,   314,
         24070,   617,  4555, 37880, 13874,  4033,   416,  7457,    13,   314,
          1101,  7926,   284,  3285,   326,    13,   775,   761,   284,  1057,
           257,  1178,  5254,   284,  5004,   262,  6287,   286,   262, 22475,
            13,   775,   481,   761,   284,  1577,   345, 45840,   516, 11711,
          9014,   284,  1037, 24773,   503,   262, 43026,    13,   775,  1183,
           635,   761,   284,   466,   339,  6759, 20781,  5254,    11,   257,
         11422,  1435,  3159,    11,   290,   257,  1844,  2910,   954,   284,
          4659,   262,  2465,    13, 12032,    11,   356,   481,   761,   284,
           466,   281, 15206,  9517,    72, 21857,    11,  3953,   534, 15701,
          1241,   290,  2198,   534,  2910,    12, 42142,  1241,    13]]), tensor([[37564,    11,   314,   423,   587, 13456,  2356,   287,   616,  5422,
           290,   616, 40333, 42093,  1283,   284,   307, 37327,    13,   314,
           892,   314,  1244,   423,   257,  3664,   452,   560, 37917,  8967,
            13,   554,  1502,   284, 37489,   534,  4006,    11,   356,   481,
           761,   284,  1620,   257,  1844,  3518,  4168,  2814,    11,  2720,
            11, 12660,    11,   290, 18103,    13, 12032,    11,   356,   743,
           761,   284,  1620,   257,  3182, 44522,   393,  2859,  1166,   284,
         10716,   262,  5676,  1989,    13, 31549, 15132,  9021,   743,   635,
           307,  2672,   319,   534,  9686,    11,  5422,    11,   290,   872,
         38621,    87,    13,   775,   815,   635,  3953,   534, 15617, 49835,
           317,    16,    66,   284,  2198,   329,   597,  2785, 19481,  3519,
           284, 12593,    13, 11399,    11,  3518,  9102, 13565,   743,  1037,
          6687,   534,  7460,    13]]), tensor([[37564,    11,   314,  1053,   587, 13456,   257,  4006,  1444,  8194,
           273, 28402,  1042,    13,  2011,  1332,  2983,   423,   407, 23667,
          6105,   656,   262,   629, 10599,   388,    13,  1867,  3315,  5254,
           466,   314,   761,   284,  1011,    30,   921,   481,   761,   284,
         17777,   257,  1844,  3518,  4168,  2814,   284,   766,   262,  6287,
           286,   262,  3318,  3798,  1631,  1332,  2983,    13,  3244,    11,
           356,   761,   284,  3189, 46487,   888,  4867,   357, 47920,  2213,
           292,   633,     8,   284,  1064,   503,   262,  2748,  4067,   286,
           262,  1332,  2983,    13,  2293,   326,    11,   257, 16176,  4703,
          2814,   290, 13621,   282, 12452,   481,   307,  1760,   284,  5004,
           611,   262,  1332,  2983,   423, 23667,   656,   262, 43510,  3814,
            13,  1002,   407,    11,   788,   584,  6375, 21546,  9021,  3519,
           284,  4257, 24678,   393, 10927,  1080,  9021,   743,   307,  2672,
            13,   775,   481,   635,   466,   281, 34266,  9102,  8922,   284,
          4659,   534,  4046,  9102,    13]]), tensor([[37564,    11,   314,  1053,   587,  1719, 23597,   290,  5894,  1108,
           287,   616, 26150,   329,   257,   981,   783,    13,   314,   635,
          1998,  2356,  1141,  1714,    13,  1867,   714,   307,   262,  1917,
           290,   644,  5254,   466,   314,   761,    30, 13403,   319,   534,
          7460,    11,   340,  5238,   588,   345,   743,   423,   379, 18191,
         14334,   259, 11815,    13,  1675,  6216,   428,    11,   356,   561,
           761,   284,  1620,   257, 43510,  2814,    11,   257, 20461, 35180,
           290,   257,  2956,  1292,  3097,    13, 12032,    11,   284,  3896,
           503,   597, 10238,  3403,   290,  4155,  9815, 37197,  1337,    11,
           314,   561,  4313,   257, 13418, 21857,    11,  9296, 12452,    11,
         13621,   282, 12452,   290,   257,  1844,  3518,  4168,  2814,    13]])]

print(len(a))
# padded_batch = torch.nn.utils.rnn.pad_sequence(a, batch_first=True, padding_value=0)
#
# print(padded_batch)  # 输出：(batch_size, max_seq_length)


def collate_fn(batch):
    # 将batch中的所有张量填充到与批次中最长张量相同的长度
    max_len = max(len(tensor) for tensor in batch)
    padded_batch = [torch.nn.functional.pad(tensor, (0, max_len - len(tensor))) for tensor in batch]

    # 将填充后的张量堆叠成一个批次张量
    return torch.stack(padded_batch)

padded_batch = collate_fn(a)
print(padded_batch)
'''


import torch
import torch.nn.functional as F

# 原始张量
tensor_122 = torch.randn(1, 122)

# 目标形状
target_shape = (1, 200)

# 计算填充的大小
padding = (0, target_shape[1] - tensor_122.size(1))

# 进行填充
padded_tensor = F.pad(tensor_122, padding)

# 输出结果
print("原始张量形状：", tensor_122.shape)
print("填充后张量形状：", padded_tensor.shape)

